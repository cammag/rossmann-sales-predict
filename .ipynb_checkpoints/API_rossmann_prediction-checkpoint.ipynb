{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aed812d5",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f7825b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T17:35:01.217490Z",
     "start_time": "2022-04-30T17:34:59.818048Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import inflection\n",
    "import math\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from IPython.core.display import HTML\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler, LabelEncoder\n",
    "from boruta import BorutaPy\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "import xgboost as xgb\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd16a802",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T23:05:39.376436Z",
     "start_time": "2022-04-29T23:05:39.373916Z"
    }
   },
   "source": [
    "## Class Rossmann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f5b994d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T00:39:41.922715Z",
     "start_time": "2022-04-30T00:39:41.904008Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import inflection\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import datetime\n",
    "\n",
    "class Rossmann (object):\n",
    "    def __init__(self):\n",
    "        self.home_path = '/home/pedro/Documentos/repos/Rossman sales project/'\n",
    "        self.competition_distance_scaler = pickle.load(open(self.home_path + 'parameter/competition_distance_scaler.pkl','rb'))\n",
    "        self.competition_time_month_scaler = pickle.load(open(self.home_path + 'parameter/competition_time_month_scaler.pkl','rb'))\n",
    "        self.promo_time_week_scaler = pickle.load(open(self.home_path + 'parameter/promo_time_week_scaler.pkl','rb'))\n",
    "        self.year_scaler = pickle.load(open(self.home_path + 'parameter/year_scaler.pkl','rb'))    \n",
    "        self.store_type_scaler = pickle.load(open(self.home_path + 'parameter/store_type_scaler.pkl','rb'))\n",
    "    \n",
    "    def data_cleaning(self,df1):\n",
    "\n",
    "        ### Rename Columns\n",
    "\n",
    "        old_cols = ['Store', 'DayOfWeek', 'Date', 'Open','Promo', 'StateHoliday', 'SchoolHoliday','StoreType', 'Assortment', 'CompetitionDistance',\n",
    "                    'CompetitionOpenSinceMonth','CompetitionOpenSinceYear', 'Promo2', 'Promo2SinceWeek','Promo2SinceYear', 'PromoInterval']\n",
    "        snakecase = lambda x: inflection.underscore(x)\n",
    "        df1.columns = list(map(snakecase,old_cols))\n",
    "\n",
    "        ### Data types and NaN values\n",
    "\n",
    "        df1['date'] = pd.to_datetime(df1['date'])\n",
    "\n",
    "        ### Fillout NaN\n",
    "\n",
    "        #competition_distance \n",
    "        df1['competition_distance'] = df1['competition_distance'].apply(lambda x: 200000 if math.isnan(x) else x)\n",
    "        #competition_open_since_month\n",
    "        df1['competition_open_since_month'] = df1.apply(lambda x: x['date'].month if math.isnan(x['competition_open_since_month']) else x['competition_open_since_month'], axis = 1)\n",
    "        #competition_open_since_year\n",
    "        df1['competition_open_since_year'] = df1.apply(lambda x: x['date'].year if math.isnan(x['competition_open_since_year']) else x['competition_open_since_year'], axis = 1)\n",
    "        #promo2_since_week\n",
    "        df1['promo2_since_week'] = df1.apply(lambda x: x['date'].week if math.isnan(x['promo2_since_week']) else x['promo2_since_week'], axis = 1)\n",
    "        #promo2_since_year       \n",
    "        df1['promo2_since_year'] = df1.apply(lambda x: x['date'].year if math.isnan(x['promo2_since_year']) else x['promo2_since_year'], axis = 1)\n",
    "        #promo_interval\n",
    "        month_map = {1: 'Jan',2: 'Feb',3: 'Mar',4: 'Apr',5: 'May',6: 'Jun',7: 'Jul',8: 'Aug',9: 'Sept',10: 'Oct',11: 'Nov',12: 'Dec'}\n",
    "\n",
    "        df1['promo_interval'].fillna(0,inplace = True)\n",
    "\n",
    "        df1['month_map'] = df1['date'].dt.month.map(month_map)\n",
    "\n",
    "        df1['is_promo'] = df1[['promo_interval','month_map']].apply(lambda x: 0 if x['promo_interval'] == 0 else 1 if x['month_map'] in x['promo_interval'].split(',') else 0, axis = 1)\n",
    "\n",
    "        ### Changing data types\n",
    "\n",
    "        df1['competition_open_since_month'] = df1['competition_open_since_month'].astype(int)\n",
    "        df1['competition_open_since_year'] = df1['competition_open_since_year'].astype(int)\n",
    "        df1['promo2_since_week'] = df1['promo2_since_week'].astype(int)\n",
    "        df1['promo2_since_year'] = df1['promo2_since_year'].astype(int)\n",
    "        \n",
    "        return df1\n",
    "    \n",
    "    def feature_engineering(self,df2):\n",
    "\n",
    "        ### Feature Engineering\n",
    "\n",
    "        #Year\n",
    "        df2['year'] = df2['date'].dt.year\n",
    "        #Month\n",
    "        df2['month'] = df2['date'].dt.month\n",
    "        #Day\n",
    "        df2['day'] = df2['date'].dt.day\n",
    "        #Week of Year\n",
    "        df2['week_of_year'] = df2['date'].dt.weekofyear\n",
    "        #Year Week\n",
    "        df2['year_week'] = df2['date'].dt.strftime('%Y-%W')\n",
    "        #Competition Since\n",
    "        df2['competition_since'] = df2.apply( lambda x: datetime.datetime(year=x['competition_open_since_year'],month=x['competition_open_since_month'],day=1 ), axis=1 )\n",
    "        df2['competition_time_month'] = ( ( df2['date'] - df2['competition_since'] )/30).apply( lambda x: x.days ).astype( int )\n",
    "        #Promo since\n",
    "        df2['promo_since'] = df2['promo2_since_year'].astype( str ) + '-' +df2['promo2_since_week'].astype( str )\n",
    "        df2['promo_since'] = df2['promo_since'].apply( lambda x: datetime.datetime.strptime( x + '-1', '%Y-%W-%w' ) - datetime.timedelta( days=7 ) )\n",
    "        df2['promo_time_week'] = ( ( df2['date'] - df2['promo_since'] )/7 ).apply(lambda x: x.days ).astype( int )\n",
    "        #Assortment\n",
    "        df2['assortment'] = df2['assortment'].apply( lambda x: 'basic' if x == 'a' else 'extra' if x == 'b' else 'extended' )\n",
    "        #State Holiday\n",
    "        df2['state_holiday'] = df2['state_holiday'].apply( lambda x: 'public_holiday'if x == 'a' else 'easter_holiday' if x == 'b' else 'christmas' if x == 'c' else 'regular_day' )\n",
    "\n",
    "        ## Variable Filtering\n",
    "\n",
    "\n",
    "        ### Selecting rows\n",
    "\n",
    "        df2 = df2[df2['open'] != 0]\n",
    "\n",
    "        ### Selecting columns\n",
    "\n",
    "        drop_cols = ['open','promo_interval','month_map']\n",
    "        df2 = df2.drop(drop_cols, axis = 1)\n",
    "        \n",
    "        return df2\n",
    "    \n",
    "    def data_preparation(self,df5):\n",
    "        \n",
    "\n",
    "        ### Rescaling\n",
    "\n",
    "        # competition distance\n",
    "        df5['competition_distance'] = self.competition_distance_scaler.fit_transform(df5[['competition_distance']].values)\n",
    "        \n",
    "        # competition time month\n",
    "        df5['competition_time_month'] = self.competition_time_month_scaler.fit_transform(df5[['competition_time_month']].values)\n",
    "\n",
    "        # promo time week\n",
    "        df5['promo_time_week'] = self.promo_time_week_scaler.fit_transform(df5[['promo_time_week']].values)\n",
    "\n",
    "        # year\n",
    "        df5['year'] = self.year_scaler.fit_transform(df5[['year']].values)\n",
    "\n",
    "        ### Transformation\n",
    "\n",
    "        #### Enconding\n",
    "\n",
    "        # state_holiday - One Hot Encoder\n",
    "        df5 = pd.get_dummies(df5,prefix=['state_holiday'],columns=['state_holiday'])\n",
    "\n",
    "        # store_type - Label Encoder\n",
    "        df5['store_type'] = self.store_type_scaler.fit_transform(df5['store_type'])\n",
    "\n",
    "        # assortment - Ordinal Encoder\n",
    "        assortment_dict = {'basic':1,'extra':2,'extended':3}\n",
    "        df5['assortment'] = df5['assortment'].map(assortment_dict)\n",
    "\n",
    "\n",
    "        #### Nature transformation\n",
    "\n",
    "        # day of week\n",
    "        df5['day_of_week_sin'] = df5['day_of_week'].apply(lambda x: np.sin(x*(2*np.pi/7)))\n",
    "        df5['day_of_week_cos'] = df5['day_of_week'].apply(lambda x: np.cos(x*(2*np.pi/7)))\n",
    "        # month\n",
    "        df5['month_sin'] = df5['month'].apply(lambda x: np.sin(x*(2*np.pi/12)))\n",
    "        df5['month_cos'] = df5['month'].apply(lambda x: np.cos(x*(2*np.pi/12)))\n",
    "        # day\n",
    "        df5['day_sin'] = df5['day'].apply(lambda x: np.sin(x*(2*np.pi/30)))\n",
    "        df5['day_cos'] = df5['day'].apply(lambda x: np.cos(x*(2*np.pi/30)))\n",
    "        # week of year\n",
    "        df5['week_of_year_sin'] = df5['week_of_year'].apply(lambda x: np.sin(x*(2*np.pi/52)))\n",
    "        df5['week_of_year_cos'] = df5['week_of_year'].apply(lambda x: np.cos(x*(2*np.pi/52)))\n",
    "        \n",
    "        cols_selected = [ 'store',\n",
    "                         'promo',\n",
    "                         'store_type',\n",
    "                         'assortment',\n",
    "                         'competition_distance',\n",
    "                         'competition_open_since_month',\n",
    "                         'competition_open_since_year',\n",
    "                         'promo2',\n",
    "                         'promo2_since_week',\n",
    "                         'promo2_since_year',\n",
    "                         'competition_time_month',\n",
    "                         'promo_time_week',\n",
    "                         'day_of_week_sin',\n",
    "                         'day_of_week_cos',\n",
    "                         'month_sin',\n",
    "                         'month_cos',\n",
    "                         'day_sin',\n",
    "                         'day_cos',\n",
    "                         'week_of_year_sin',\n",
    "                         'week_of_year_cos' ]\n",
    "        \n",
    "        return df5[cols_selected]\n",
    "    \n",
    "    def get_prediction(self,model,original_data,test_data):\n",
    "        # prediction\n",
    "        pred = model.predict(test_data)\n",
    "        \n",
    "        # join pred into the original data\n",
    "        original_data['prediction'] = np.expm1(pred)\n",
    "        \n",
    "        return original_data.to_json(orient='records',date_format = 'iso')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1641d4",
   "metadata": {},
   "source": [
    "## API handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "50cd958c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T00:56:39.254365Z",
     "start_time": "2022-04-30T00:56:39.227475Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'rossmann'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [37]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mflask\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Flask, request, Response\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrossmann\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mRossmann\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Rossmann\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# loading model\u001b[39;00m\n\u001b[1;32m      7\u001b[0m model \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/pedro/Documentos/repos/Rossman sales project/model_rossman.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'rossmann'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from flask import Flask, request, Response\n",
    "from rossmann.Rossmann import Rossmann\n",
    "\n",
    "# loading model\n",
    "model = pickle.load(open('/home/pedro/Documentos/repos/Rossman sales project/model_rossman.pkl','rb'))\n",
    "\n",
    "# initialize API\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/rossmann/predict',methods = ['POST'])\n",
    "\n",
    "def rossmann_predict():\n",
    "    test_json = request.get_json()\n",
    "    \n",
    "    if test_json: # there is data\n",
    "        if isinstance(test_json, dict): # Unique example\n",
    "            test_raw = pd.DataFrame(test_jason,index = [0])\n",
    "        \n",
    "        else: # Multiple examples\n",
    "            teste_raw = pd.DataFrame(test_json, columns = test_json[0].keys())\n",
    "            \n",
    "        # Instatiate Rossmann class\n",
    "        pipeline = Rossmann()\n",
    "        \n",
    "        # data cleaning\n",
    "        df1 = pipeline.data_cleaning(teste_raw)\n",
    "        \n",
    "        # feature engineering\n",
    "        df2 = pipeline.feature_engineering(df1)\n",
    "        \n",
    "        # data preparation\n",
    "        df3 = pipeline.data_preparation(df2)\n",
    "        \n",
    "        # prediction\n",
    "        df_response = pipeline.get_prediction(model,teste_raw,df3)\n",
    "        \n",
    "        return df_response\n",
    "        \n",
    "    else:\n",
    "        return Response('{}', status = 200, mimetype = 'application/json')\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run('0.0.0.0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1972a79",
   "metadata": {},
   "source": [
    "## API Tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a043887",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T17:35:26.407339Z",
     "start_time": "2022-04-30T17:35:26.362100Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42bfa8e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T17:35:26.946981Z",
     "start_time": "2022-04-30T17:35:26.920105Z"
    }
   },
   "outputs": [],
   "source": [
    "# loading test data set\n",
    "df10 = pd.read_csv('Ross_data/test.csv')\n",
    "df_store_raw = pd.read_csv('Ross_data/store.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a100edcb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T17:41:12.869339Z",
     "start_time": "2022-04-30T17:41:12.854837Z"
    }
   },
   "outputs": [],
   "source": [
    "# merge test data + store\n",
    "df_test = pd.merge(df10,df_store_raw,how = 'left',on='Store')\n",
    "\n",
    "# choose store for prediction\n",
    "df_test = df_test[df_test['Store'].isin([20,23,22])]\n",
    "\n",
    "# remove closed days\n",
    "df_test = df_test[df_test['Open'] != 0]\n",
    "df_test = df_test[~df_test['Open'].isnull()]\n",
    "df_test = df_test.drop('Id',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3da257d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T17:41:13.225653Z",
     "start_time": "2022-04-30T17:41:13.219402Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert DataFrame to json\n",
    "data = json.dumps(df_test.to_dict(orient='records'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "698e88ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T17:41:15.351291Z",
     "start_time": "2022-04-30T17:41:14.149219Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code 200\n"
     ]
    }
   ],
   "source": [
    "# API Call\n",
    "#url = 'http://0.0.0.0:5000/rossmann/predict'\n",
    "url = 'https://prediction-rossmann-model-test.herokuapp.com/rossmann/predict'\n",
    "header = {'Content-type': 'application/json' }\n",
    "data = data\n",
    "r = requests.post( url, data=data, headers=header )\n",
    "print( 'Status Code {}'.format( r.status_code ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ee9a5092",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T17:41:15.775903Z",
     "start_time": "2022-04-30T17:41:15.767262Z"
    }
   },
   "outputs": [],
   "source": [
    "d1 = pd.DataFrame(r.json(),columns=r.json()[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4ef48939",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T17:41:16.555149Z",
     "start_time": "2022-04-30T17:41:16.548479Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Store number 20 will sell R$295,864.54 in the next 6 weeks\n",
      "Store number 22 will sell R$217,901.74 in the next 6 weeks\n",
      "Store number 23 will sell R$227,984.94 in the next 6 weeks\n"
     ]
    }
   ],
   "source": [
    "d2 = d1[['store','prediction']].groupby('store').sum().reset_index()\n",
    "\n",
    "for i in range(len(d2)):\n",
    "    print('Store number {} will sell R${:,.2f} in the next 6 weeks'.format(d2.loc[i,'store'],d2.loc[i,'prediction']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7c0f87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
